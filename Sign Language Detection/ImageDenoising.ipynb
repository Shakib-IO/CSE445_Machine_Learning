{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageDenoising.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPTYCo7HL54a",
        "outputId": "d7afdeed-5e30-4b9a-cfa6-30c2ac66614d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PjIbIncL8Gm"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dspqgHkMAiS",
        "outputId": "7ee03261-bbda-46bf-acde-73da9bf26269"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YT3-ky3Ne4G",
        "outputId": "ebf0285b-96ab-4340-d91d-8dce1c02837a"
      },
      "source": [
        "cd data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlYXWZrbNgWm"
      },
      "source": [
        "!mkdir train\n",
        "!mkdir test\n",
        "!mkdir valid"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vpTtGwMNn2F",
        "outputId": "619b56b8-7525-46af-84e6-38a0ea9cd3aa"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  valid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMqLgt8-KHhb"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZTQjBhAL4sz"
      },
      "source": [
        "dataset_path = 'data/images'\n",
        "batch_size = 20\n",
        "epochs = 150\n",
        "input_shape = (256, 256)\n",
        "noise_factor = 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbqgMVD2Ma7b"
      },
      "source": [
        "DataGenerator\n",
        "\n",
        "Add random crop functionality\n",
        "\n",
        "Add random crop fucntionality to Keras' ImageDataGenerator by overriding 'load_img' method in its module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi0m0lIlMaC3"
      },
      "source": [
        "from PIL import Image as pil_image\n",
        "\n",
        "def random_crop(img, random_crop_size):\n",
        "    width, height = img.size # PIL format\n",
        "    dx, dy = random_crop_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    return img.crop((x, y, x+dx, y+dy))\n",
        "\n",
        "\n",
        "def load_img_extended(path, grayscale=False, color_mode='rgb', target_size=None,\n",
        "                      interpolation='nearest'):\n",
        "    if grayscale is True:\n",
        "        warnings.warn('grayscale is deprecated. Please use '\n",
        "                      'color_mode = \"grayscale\"')\n",
        "        color_mode = 'grayscale'\n",
        "    if pil_image is None:\n",
        "        raise ImportError('Could not import PIL.Image. '\n",
        "                          'The use of `array_to_img` requires PIL.')\n",
        "    img = pil_image.open(path)\n",
        "    if color_mode == 'grayscale':\n",
        "        if img.mode != 'L':\n",
        "            img = img.convert('L')\n",
        "    elif color_mode == 'rgba':\n",
        "        if img.mode != 'RGBA':\n",
        "            img = img.convert('RGBA')\n",
        "    elif color_mode == 'rgb':\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "    else:\n",
        "        raise ValueError('color_mode must be \"grayscale\", \"rbg\", or \"rgba\"')\n",
        "    \n",
        "    if target_size is not None:\n",
        "        width_height_tuple = (target_size[1], target_size[0])\n",
        "        if img.size != width_height_tuple:\n",
        "            img = random_crop(img, width_height_tuple) # here comes the magic\n",
        "    return img"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44YZPK0LMnxf"
      },
      "source": [
        "**ImageDataGenerator**\n",
        "\n",
        "ImageDataGenerator arguments:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SBqajSHMnlc"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_gen_args = dict(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.5, 1.2],\n",
        "    shear_range=0.01,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1/255,\n",
        "    fill_mode='reflect',\n",
        "    data_format='channels_last')\n",
        "\n",
        "data_flow_args = dict(\n",
        "    target_size=input_shape,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input') "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt1kgo3rM1o5"
      },
      "source": [
        "Add gaussian noise to the input after augmentations have taken place.\n",
        "\n",
        "Inspired by https://jkjung-avt.github.io/keras-image-cropping/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhpurTXpMwHV"
      },
      "source": [
        "def noisy_generator(batches):\n",
        "    for batch_x, batch_y in batches:\n",
        "        sigma = np.random.exponential(0.15)\n",
        "        noise = noise_factor * np.random.normal(scale=sigma, size=batch_x.shape)\n",
        "        batch_noisy = np.clip(batch_x + noise, 0, 1)\n",
        "        yield (batch_noisy, batch_y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spxwtoNcM922"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMffcX7NM9aj"
      },
      "source": [
        "import keras.layers as layers\n",
        "import keras.models as models\n",
        "from keras.initializers import orthogonal\n",
        "\n",
        "\n",
        "def Conv2DLayer(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
        "    prefix = f'block_{block_id}_'\n",
        "    x = layers.Conv2D(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_init, name=prefix+'conv')(x)\n",
        "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
        "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
        "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
        "    return x\n",
        "\n",
        "def Transpose_Conv2D(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
        "    prefix = f'block_{block_id}_'\n",
        "    x = layers.Conv2DTranspose(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
        "                               kernel_initializer=kernel_init, name=prefix+'de-conv')(x)\n",
        "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
        "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
        "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def AutoEncdoer(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    \n",
        "    # 256 x 256\n",
        "    conv1 = Conv2DLayer(inputs, 64, 3, strides=1, padding='same', block_id=1)\n",
        "    conv2 = Conv2DLayer(conv1, 64, 3, strides=2, padding='same', block_id=2)\n",
        "    \n",
        "    # 128 x 128\n",
        "    conv3 = Conv2DLayer(conv2, 128, 5, strides=2, padding='same', block_id=3)\n",
        "    \n",
        "    # 64 x 64\n",
        "    conv4 = Conv2DLayer(conv3, 128, 3, strides=1, padding='same', block_id=4)\n",
        "    conv5 = Conv2DLayer(conv4, 256, 5, strides=2, padding='same', block_id=5)\n",
        "    \n",
        "    # 32 x 32\n",
        "    conv6 = Conv2DLayer(conv5, 512, 3, strides=2, padding='same', block_id=6)\n",
        "    \n",
        "    # 16 x 16\n",
        "    deconv1 = Transpose_Conv2D(conv6, 512, 3, strides=2, padding='same', block_id=7)\n",
        "    \n",
        "    # 32 x 32\n",
        "    skip1 = layers.concatenate([deconv1, conv5], name='skip1')\n",
        "    conv7 = Conv2DLayer(skip1, 256, 3, strides=1, padding='same', block_id=8)\n",
        "    deconv2 = Transpose_Conv2D(conv7, 128, 3, strides=2, padding='same', block_id=9)\n",
        "    \n",
        "    # 64 x 64\n",
        "    skip2 = layers.concatenate([deconv2, conv3], name='skip2')\n",
        "    conv8 = Conv2DLayer(skip2, 128, 5, strides=1, padding='same', block_id=10)\n",
        "    deconv3 = Transpose_Conv2D(conv8, 64, 3, strides=2, padding='same', block_id=11)\n",
        "    \n",
        "    # 128 x 128\n",
        "    skip3 = layers.concatenate([deconv3, conv2], name='skip3')\n",
        "    conv9 = Conv2DLayer(skip3, 64, 5, strides=1, padding='same', block_id=12)\n",
        "    deconv4 = Transpose_Conv2D(conv9, 64, 3, strides=2, padding='same', block_id=13)\n",
        "    \n",
        "    # 256 x 256\n",
        "    skip3 = layers.concatenate([deconv4, conv1])\n",
        "    conv10 = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid',\n",
        "                       kernel_initializer=orthogonal(), name='final_conv')(skip3)\n",
        "\n",
        "    \n",
        "    return models.Model(inputs=inputs, outputs=conv10)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaq4WyPcNINZ"
      },
      "source": [
        "tt = '/content/data/images/train'\n",
        "vv = '/content/data/images/valid'\n",
        "\n",
        "train_datagen = ImageDataGenerator(**data_gen_args)\n",
        "val_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "    dataset_path + '/tt',\n",
        "    **data_flow_args)\n",
        "\n",
        "val_batches = val_datagen.flow_from_directory(\n",
        "    dataset_path + '/vv',\n",
        "    **data_flow_args)\n",
        "\n",
        "\n",
        "train_noisy_batches = noisy_generator(train_batches)\n",
        "val_noisy_batches = noisy_generator(val_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hbhGIS_NI6I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}